{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSE-4076 Lab Assignment 6\n",
    "Devadharsanan 21MIA1163"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to video file\n",
    "video_path = r\"C:\\Users\\devadharsanan\\Videos\\person_tracking.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video was loaded successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "else:\n",
    "    print(\"Video loaded successfully.\")\n",
    "\n",
    "# Background subtractor for motion detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "# Loop through frames\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame for faster processing\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours for motion detection\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Person\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display frame with annotations\n",
    "    cv2.imshow(\"Person Tracking\", frame)\n",
    "\n",
    "    # Update frame count and progress\n",
    "    frame_count += 1\n",
    "    print(f\"Processing frame {frame_count}\", end=\"\\r\")\n",
    "\n",
    "    # Exit condition\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Path to video file\n",
    "video_path = r\"C:\\Users\\devadharsanan\\Videos\\shopping_area.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Verify video load success\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "else:\n",
    "    print(\"Video loaded successfully.\")\n",
    "\n",
    "# Video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frames_per_interval = fps * 120  # 2-minute intervals\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Track people count over intervals\n",
    "people_count_per_interval = []\n",
    "frame_count = 0\n",
    "current_interval_count = 0\n",
    "\n",
    "# Process each frame\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame and apply background subtraction\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours to detect people\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    people_count = sum(1 for c in contours if cv2.contourArea(c) > 500)\n",
    "\n",
    "    # Accumulate people count for current interval\n",
    "    current_interval_count += people_count\n",
    "    frame_count += 1\n",
    "\n",
    "    # If end of interval reached, save count and reset for next interval\n",
    "    if frame_count % frames_per_interval == 0:\n",
    "        people_count_per_interval.append(current_interval_count)\n",
    "        current_interval_count = 0\n",
    "        print(f\"Interval {len(people_count_per_interval)}: {people_count_per_interval[-1]} people\")\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(people_count_per_interval, marker='o')\n",
    "plt.title(\"People Count Over Time Intervals\")\n",
    "plt.xlabel(\"Time Interval\")\n",
    "plt.ylabel(\"People Count\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Paths to reference image and video\n",
    "reference_image_path = r\"C:\\Users\\devadharsanan\\Pictures\\reference_face.jpg\"\n",
    "video_path = r\"C:\\Users\\devadharsanan\\Videos\\faces_video.mp4\"\n",
    "\n",
    "# Load face cascade and reference image\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "ref_img = cv2.imread(reference_image_path, 0)\n",
    "\n",
    "# Detect face in the reference image\n",
    "faces = face_cascade.detectMultiScale(ref_img, scaleFactor=1.1, minNeighbors=5)\n",
    "if len(faces) > 0:\n",
    "    (x, y, w, h) = faces[0]\n",
    "    ref_face = ref_img[y:y + h, x:x + w]\n",
    "else:\n",
    "    print(\"Error: No face detected in the reference image.\")\n",
    "    exit()\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale and detect faces\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Match each detected face to reference face\n",
    "    for (x, y, w, h) in faces:\n",
    "        detected_face = gray_frame[y:y + h, x:x + w]\n",
    "        match = cv2.matchTemplate(detected_face, ref_face, cv2.TM_CCOEFF_NORMED)\n",
    "        if match >= 0.6:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Suspect\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with matched faces\n",
    "    cv2.imshow(\"Suspect Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "video_path = r\"C:\\Users\\devadharsanan\\Videos\\entry_exit.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "entries, exits = 0, 0\n",
    "entry_y, exit_y = 200, 100\n",
    "\n",
    "# Ensure video loads\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Track and count entries/exits\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 1000:\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            center_y = y + h // 2\n",
    "            if center_y > entry_y:\n",
    "                entries += 1\n",
    "            elif center_y < exit_y:\n",
    "                exits += 1\n",
    "\n",
    "    # Display counts on frame\n",
    "    cv2.putText(frame, f\"Entries: {entries}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Exits: {exits}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Entry/Exit Counter\", frame)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "video_path = r\"C:\\Users\\devadharsanan\\Videos\\mall_dwell_time.mp4\"\n",
    "output_folder = r\"C:\\Users\\devadharsanan\\Documents\\dwelling_time_results\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "entry_times, dwell_times = {}, {}\n",
    "tracked_positions = {}\n",
    "entity_id_counter = 1\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        entity_id = None\n",
    "        for eid, (ex, ey, ew, eh) in tracked_positions.items():\n",
    "            if abs(x - ex) < 50 and abs(y - ey) < 50:\n",
    "                entity_id = eid\n",
    "                break\n",
    "        if entity_id is None:\n",
    "            entity_id = entity_id_counter\n",
    "            entry_times[entity_id] = time.time()\n",
    "            tracked_positions[entity_id] = (x, y, w, h)\n",
    "            entity_id_counter += 1\n",
    "        dwell_times[entity_id] = time.time() - entry_times[entity_id]\n",
    "        cv2.putText(frame, f\"Time: {dwell_times[entity_id]:.1f}s\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Dwelling Time Tracker\", frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save dwelling times to a CSV\n",
    "pd.DataFrame([{'Entity ID': eid, 'Dwelling Time': t} for eid, t in dwell_times.items()]).to_csv(os.path.join(output_folder, 'dwelling_times.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the video\n",
    "video_path = r\"C:\\Users\\devadharsanan\\Downloads\\in.mp4\"\n",
    "output_folder = 'frames'\n",
    "\n",
    "# Create a folder to save frames if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Loop through each frame in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # If a frame is returned\n",
    "        if ret:\n",
    "            # Define filename for each frame\n",
    "            frame_filename = os.path.join(output_folder, f'frame_{frame_count:04d}.jpg')\n",
    "            \n",
    "            # Save the frame as an image file\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            frame_count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    print(f\"Total frames saved: {frame_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to input and output folders\n",
    "input_folder = 'frames'\n",
    "output_folder = 'detected_cars_frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize background subtractor for motion detection\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "# Loop through the saved frames\n",
    "for frame_file in sorted(os.listdir(input_folder)):\n",
    "    frame_path = os.path.join(input_folder, frame_file)\n",
    "    frame = cv2.imread(frame_path)\n",
    "\n",
    "    # Check if frame is loaded successfully\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "    \n",
    "    # Threshold the mask to binary to get clean detection areas\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours to detect moving cars\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detected = False\n",
    "    for cnt in contours:\n",
    "        # Filter out small areas to ignore noise\n",
    "        if cv2.contourArea(cnt) > 500:  # Adjust area threshold based on car size\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            # Draw bounding box on the frame (optional for visualization)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            detected = True\n",
    "\n",
    "    # If any cars were detected in the frame, save it\n",
    "    if detected:\n",
    "        output_path = os.path.join(output_folder, frame_file)\n",
    "        cv2.imwrite(output_path, frame)\n",
    "\n",
    "print(\"Car detection complete. Frames with detected cars are saved in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Paths to input and output folders\n",
    "input_folder = 'frames'\n",
    "output_folder = 'categorized_cars'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize background subtractor\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "# Define color ranges for various colors\n",
    "color_ranges = {\n",
    "    \"red\": ((0, 100, 100), (10, 255, 255)),\n",
    "    \"orange\": ((10, 100, 100), (25, 255, 255)),\n",
    "    \"yellow\": ((25, 100, 100), (35, 255, 255)),\n",
    "    \"green\": ((35, 50, 50), (85, 255, 255)),\n",
    "    \"cyan\": ((85, 100, 100), (95, 255, 255)),\n",
    "    \"blue\": ((95, 150, 0), (125, 255, 255)),\n",
    "    \"purple\": ((125, 100, 100), (150, 255, 255)),\n",
    "    \"pink\": ((150, 100, 100), (170, 255, 255)),\n",
    "    \"white\": ((0, 0, 200), (180, 30, 255)),  # Bright area with low saturation\n",
    "    \"gray\": ((0, 0, 50), (180, 20, 200)),    # Low saturation, moderate brightness\n",
    "    \"black\": ((0, 0, 0), (180, 255, 50)),    # Very low brightness\n",
    "}\n",
    "\n",
    "# Process each saved frame\n",
    "car_count = 0\n",
    "for frame_file in sorted(os.listdir(input_folder)):\n",
    "    frame_path = os.path.join(input_folder, frame_file)\n",
    "    frame = cv2.imread(frame_path)\n",
    "\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    # Apply background subtraction to detect moving objects\n",
    "    fg_mask = background_subtractor.apply(frame)\n",
    "    _, fg_mask = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours of moving objects\n",
    "    contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        # Filter out small contours to remove noise\n",
    "        if cv2.contourArea(cnt) > 500:  # Adjust based on car size\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            car_region = frame[y:y + h, x:x + w]\n",
    "\n",
    "            # Convert to HSV for color-based classification\n",
    "            hsv = cv2.cvtColor(car_region, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Determine car color\n",
    "            car_color = \"unknown\"\n",
    "            for color_name, (lower, upper) in color_ranges.items():\n",
    "                mask = cv2.inRange(hsv, lower, upper)\n",
    "                if cv2.countNonZero(mask) > 500:  # Adjust threshold as needed\n",
    "                    car_color = color_name\n",
    "                    break\n",
    "\n",
    "            # Save categorized frame with color label\n",
    "            car_count += 1\n",
    "            output_path = os.path.join(output_folder, f'{car_color}_car_{car_count:04d}.jpg')\n",
    "            cv2.imwrite(output_path, car_region)\n",
    "\n",
    "print(\"Car detection and categorization complete. Categorized frames are saved in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Paths to input images and output folder for unique cars\n",
    "input_folder = 'categorized_cars'\n",
    "unique_folder = 'unique_cars'\n",
    "os.makedirs(unique_folder, exist_ok=True)\n",
    "\n",
    "# Set minimum dimensions for an image to be considered\n",
    "min_width, min_height = 100, 100  # Adjust based on your images\n",
    "\n",
    "# Threshold for SSIM similarity to consider two images as duplicates\n",
    "similarity_threshold = 0.8\n",
    "\n",
    "# Set a common size for all images for SSIM comparison\n",
    "fixed_size = (200, 200)\n",
    "\n",
    "# Function to check similarity between two images using SSIM\n",
    "def are_images_similar(img1, img2, threshold=similarity_threshold):\n",
    "    # Resize both images to the fixed size\n",
    "    img1_resized = cv2.resize(img1, fixed_size)\n",
    "    img2_resized = cv2.resize(img2, fixed_size)\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    img1_gray = cv2.cvtColor(img1_resized, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute SSIM between the resized grayscale images\n",
    "    s = ssim(img1_gray, img2_gray)\n",
    "    return s > threshold\n",
    "\n",
    "# List to store unique images\n",
    "unique_images = []\n",
    "car_count = 0\n",
    "\n",
    "# Process each image in the input folder\n",
    "for image_file in sorted(os.listdir(input_folder)):\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Skip images that are too small\n",
    "    if image.shape[1] < min_width or image.shape[0] < min_height:\n",
    "        continue\n",
    "\n",
    "    # Compare with existing unique images\n",
    "    is_unique = True\n",
    "    for unique_image in unique_images:\n",
    "        if are_images_similar(image, unique_image):\n",
    "            is_unique = False\n",
    "            break\n",
    "\n",
    "    # If image is unique, add it to the unique images list and save it\n",
    "    if is_unique:\n",
    "        unique_images.append(image)\n",
    "        car_count += 1\n",
    "        output_path = os.path.join(unique_folder, f'unique_car_{car_count:04d}.jpg')\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "print(f\"Unique car detection complete. Total unique cars counted: {car_count}\")\n",
    "print(\"Unique car images are saved in:\", unique_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Paths to the input and output folders\n",
    "input_folder = 'unique_cars'\n",
    "distinct_folder = 'distinct_cars'\n",
    "os.makedirs(distinct_folder, exist_ok=True)\n",
    "\n",
    "# Threshold for SSIM similarity to consider two images as duplicates\n",
    "similarity_threshold = 0.4\n",
    "\n",
    "# Minimum dimensions for an image to be considered distinct\n",
    "min_width, min_height = 200, 150\n",
    "\n",
    "# Set a common size for all images for SSIM comparison\n",
    "fixed_size = (200, 200)\n",
    "\n",
    "# Define a threshold for color similarity (Euclidean distance in RGB space)\n",
    "color_similarity_threshold = 50\n",
    "\n",
    "# Function to get the dominant color of an image\n",
    "def get_dominant_color(image, k=1):\n",
    "    # Resize image to speed up processing\n",
    "    img = cv2.resize(image, (100, 100))\n",
    "    img = img.reshape((-1, 3))\n",
    "\n",
    "    # Apply k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(img)\n",
    "    dominant_color = kmeans.cluster_centers_[0]\n",
    "    return dominant_color\n",
    "\n",
    "# Function to check similarity between two images using SSIM\n",
    "def are_images_similar(img1, img2, threshold=similarity_threshold):\n",
    "    # Resize both images to the fixed size\n",
    "    img1_resized = cv2.resize(img1, fixed_size)\n",
    "    img2_resized = cv2.resize(img2, fixed_size)\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    img1_gray = cv2.cvtColor(img1_resized, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2_resized, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute SSIM between the resized grayscale images\n",
    "    s = ssim(img1_gray, img2_gray)\n",
    "    return s > threshold\n",
    "\n",
    "# Function to calculate the Euclidean distance between two RGB colors\n",
    "def color_distance(color1, color2):\n",
    "    return np.linalg.norm(color1 - color2)\n",
    "\n",
    "# List to store unique images and their dominant colors\n",
    "distinct_images = []\n",
    "distinct_colors = []\n",
    "distinct_count = 0\n",
    "\n",
    "# Process each image in the unique_cars folder\n",
    "for image_file in sorted(os.listdir(input_folder)):\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Skip images that are smaller than the specified dimensions\n",
    "    if image.shape[1] < min_width or image.shape[0] < min_height:\n",
    "        continue\n",
    "\n",
    "    # Calculate the dominant color of the current image\n",
    "    dominant_color = get_dominant_color(image)\n",
    "\n",
    "    # Compare with existing distinct images\n",
    "    is_distinct = True\n",
    "    for i, distinct_image in enumerate(distinct_images):\n",
    "        # Check if images are similar based on SSIM\n",
    "        if are_images_similar(image, distinct_image):\n",
    "            # Check if dominant colors are also similar\n",
    "            if color_distance(dominant_color, distinct_colors[i]) < color_similarity_threshold:\n",
    "                is_distinct = False\n",
    "                break\n",
    "\n",
    "    # If image is distinct, add it to the distinct images list and save it\n",
    "    if is_distinct:\n",
    "        distinct_images.append(image)\n",
    "        distinct_colors.append(dominant_color)\n",
    "        distinct_count += 1\n",
    "        output_path = os.path.join(distinct_folder, f'distinct_car_{distinct_count:04d}.jpg')\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "print(f\"Filtering complete. Total distinct cars saved: {distinct_count}\")\n",
    "print(\"Distinct car images are saved in:\", distinct_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Paths to input folder and output folder for unique color cars\n",
    "input_folder = 'distinct_cars'\n",
    "output_folder = 'unique_color_cars'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a threshold for color similarity (Euclidean distance in RGB space)\n",
    "color_similarity_threshold = 50\n",
    "\n",
    "# Function to get the dominant color of an image\n",
    "def get_dominant_color(image, k=1):\n",
    "    # Resize image to speed up processing\n",
    "    img = cv2.resize(image, (100, 100))\n",
    "    img = img.reshape((-1, 3))\n",
    "\n",
    "    # Apply k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(img)\n",
    "    dominant_color = kmeans.cluster_centers_[0]\n",
    "    return dominant_color\n",
    "\n",
    "# Function to calculate the Euclidean distance between two RGB colors\n",
    "def color_distance(color1, color2):\n",
    "    return np.linalg.norm(color1 - color2)\n",
    "\n",
    "# List to store unique colors and their corresponding images\n",
    "unique_colors = []\n",
    "car_count = 0\n",
    "\n",
    "# Process each image in the distinct_cars folder\n",
    "for image_file in sorted(os.listdir(input_folder)):\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Calculate the dominant color of the current image\n",
    "    dominant_color = get_dominant_color(image)\n",
    "\n",
    "    # Check if this dominant color is similar to any previously saved unique color\n",
    "    is_unique_color = True\n",
    "    for color in unique_colors:\n",
    "        if color_distance(dominant_color, color) < color_similarity_threshold:\n",
    "            is_unique_color = False\n",
    "            break\n",
    "\n",
    "    # If the color is unique, save the image and add the color to the list\n",
    "    if is_unique_color:\n",
    "        unique_colors.append(dominant_color)\n",
    "        car_count += 1\n",
    "        output_path = os.path.join(output_folder, f'unique_color_car_{car_count:04d}.jpg')\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "print(f\"Color-based filtering complete. Total unique color cars saved: {car_count}\")\n",
    "print(\"Unique color car images are saved in:\", output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
